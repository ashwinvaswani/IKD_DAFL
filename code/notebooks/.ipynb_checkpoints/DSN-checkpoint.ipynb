{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Het-Shah/IKD_DAFL/blob/master/code/notebooks/DSN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FEqjyuOel0HO"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pqkJI5Gt7Mmk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "AxY2TMbdSBHD",
    "outputId": "9965ffb7-78c8-4a41-b73f-f55e8d402f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Mar 16 17:51:21 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.59       Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ohnjQNcsxnLh"
   },
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mS8QSUVBp6Ps"
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self,params):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, params[0], kernel_size=(5, 5))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.conv2 = nn.Conv2d(params[0], params[1], kernel_size=(5, 5))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.conv3 = nn.Conv2d(params[1], params[2], kernel_size=(5, 5))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(params[2], params[3])\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(params[3], 10)\n",
    "\n",
    "    def forward(self, img, out_feature=False):\n",
    "        output = self.conv1(img)\n",
    "        output = self.relu1(output)\n",
    "        output = self.maxpool1(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "        output = self.maxpool2(output)\n",
    "        output = self.conv3(output)\n",
    "        output = self.relu3(output)\n",
    "        feature = output.view(-1, 120)\n",
    "        output = self.fc1(feature)\n",
    "        output = self.relu4(output)\n",
    "        output = self.fc2(output)\n",
    "        if out_feature == False:\n",
    "            return output\n",
    "        else:\n",
    "            return output,feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01SefQm0qYZ3"
   },
   "outputs": [],
   "source": [
    "original_parameters = [6,16,120,84]\n",
    "net = LeNet5(original_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "0-4jGQtyqkgM",
    "outputId": "dcb2d2ac-35bb-4cf2-eb98-8eaf76d523c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet5(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu3): ReLU()\n",
       "  (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "colab_type": "code",
    "id": "E0Rh0TO8qk_y",
    "outputId": "be9793a1-5782-4de9-866f-df24cf149773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original network: \n",
      "LeNet5(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "At depth 1: \n",
      "[3, 8, 60, 42]\n",
      "LeNet5(\n",
      "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(8, 60, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (fc1): Linear(in_features=60, out_features=42, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc2): Linear(in_features=42, out_features=10, bias=True)\n",
      ")\n",
      "At depth 2: \n",
      "[1, 4, 30, 21]\n",
      "LeNet5(\n",
      "  (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu1): ReLU()\n",
      "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu2): ReLU()\n",
      "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(4, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (relu3): ReLU()\n",
      "  (fc1): Linear(in_features=30, out_features=21, bias=True)\n",
      "  (relu4): ReLU()\n",
      "  (fc2): Linear(in_features=21, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "original_parameters = [6,16,120,84]\n",
    "for depth in range(3):\n",
    "  if depth == 0:\n",
    "    print(\"Original network: \")\n",
    "    net = LeNet5(original_parameters)\n",
    "    print(net)\n",
    "  else:\n",
    "    print(\"At depth \" + str(depth) + \": \")\n",
    "    original_parameters = [int(i/2) for i in original_parameters]\n",
    "    print(original_parameters)\n",
    "    net = LeNet5(original_parameters)\n",
    "    print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O-WT3_hBxeju"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m_wLLvKwxiW5"
   },
   "source": [
    "# VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Is025MbsBiJ"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, params, num_classes=10, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(params[0] * 7 * 7, params[1]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(params[1], params[2]),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(params[2], num_classes),\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CEpzz-8CvcJ1"
   },
   "outputs": [],
   "source": [
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def _vgg(arch, cfg,params, batch_norm, pretrained, progress, **kwargs):\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfg, batch_norm=batch_norm),params = params, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LT-xS2j7vFa7"
   },
   "outputs": [],
   "source": [
    "def vgg16(features,params,pretrained=False,progress=True, **kwargs):\n",
    "    return _vgg('vgg16', features, params, False, pretrained, progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy3P2cpv1swZ"
   },
   "outputs": [],
   "source": [
    "def get_output_nodes(params):\n",
    "  for i in reversed(params):\n",
    "    if type(i) == int:\n",
    "      last_number = i\n",
    "      break\n",
    "\n",
    "  return last_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHzJ1ST07zEN"
   },
   "source": [
    "# Testing on Cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxoE5L9071Ro"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139,
     "referenced_widgets": [
      "b71206812cc44b4da6e97bd31a779585",
      "eee4951ca462479193a3b7c9b1c55c61",
      "c66829a33d8d406e90d70461cd870b73",
      "7f5c2d4d2c1a478cb3005665193c823a",
      "24d8a07a1f724e28b30eea8c99924015",
      "5d11e61192804e7aac33b2e829f5b66d",
      "671b129abce54c699b860d3b537bfcab",
      "46a08e246bdd4179abe250ceb801b81f"
     ]
    },
    "colab_type": "code",
    "id": "k5MhrcVf73Ls",
    "outputId": "463518c1-840f-4bc6-c981-f0ee026c8f03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71206812cc44b4da6e97bd31a779585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data/cifar-10-python.tar.gz to data\n",
      "Calculated means: [0.49139968 0.48215841 0.44653091]\n",
      "Calculated stds: [0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(root = 'data', \n",
    "                              train = True, \n",
    "                              download = True)\n",
    "\n",
    "means = train_data.data.mean(axis = (0,1,2)) / 255\n",
    "stds = train_data.data.std(axis = (0,1,2)) / 255\n",
    "\n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSTJ5euT78tf"
   },
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.RandomRotation(10),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = means, \n",
    "                                                std = stds)\n",
    "                       ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = means, \n",
    "                                                std = stds)\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "zvNdXqc68A50",
    "outputId": "67fb79d0-1f5a-403d-dd3c-bc8159907e94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10('data', \n",
    "                              train = True, \n",
    "                              download = True, \n",
    "                              transform = train_transforms)\n",
    "\n",
    "test_data = datasets.CIFAR10('data', \n",
    "                             train = False, \n",
    "                             download = True, \n",
    "                             transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XpdRreU8Ezd"
   },
   "outputs": [],
   "source": [
    "n_train_examples = int(len(train_data)*0.9)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = torch.utils.data.random_split(train_data, \n",
    "                                                       [n_train_examples, n_valid_examples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "r90hhoce8Ho-",
    "outputId": "d102ef82-aa1f-404e-bab2-7519a4d8ab99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 45000\n",
      "Number of validation examples: 5000\n",
      "Number of testing examples: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYNGQP6e8MQW"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_iterator = torch.utils.data.DataLoader(train_data, \n",
    "                                             shuffle = True, \n",
    "                                             batch_size = BATCH_SIZE)\n",
    "\n",
    "valid_iterator = torch.utils.data.DataLoader(valid_data, \n",
    "                                             batch_size = BATCH_SIZE)\n",
    "\n",
    "test_iterator = torch.utils.data.DataLoader(test_data, \n",
    "                                            batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dC7ZSF4HCwmg"
   },
   "source": [
    "# Building model and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "45Iyu4ru9zFJ"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "    model = model.to(device)\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMz3Xj_T-CVV"
   },
   "outputs": [],
   "source": [
    "dataloaders_dict = {'train':train_iterator,'val':valid_iterator}\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 10\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 8\n",
    "\n",
    "# Number of epochs to train for\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Jigw4u4yeYAa",
    "outputId": "3cfea3f9-274d-406d-d638-668fa010eafc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At depth 2: \n",
      "Removing last layer: \n",
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 2.3026 Acc: 0.0996\n",
      "val Loss: 2.3025 Acc: 0.1022\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 2.3025 Acc: 0.1009\n",
      "val Loss: 2.3024 Acc: 0.0878\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 2.3024 Acc: 0.1019\n",
      "val Loss: 2.3023 Acc: 0.0996\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 2.3023 Acc: 0.1042\n",
      "val Loss: 2.3022 Acc: 0.1006\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 2.3021 Acc: 0.1084\n",
      "val Loss: 2.3021 Acc: 0.1012\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 2.3020 Acc: 0.1104\n",
      "val Loss: 2.3020 Acc: 0.1012\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 2.3019 Acc: 0.1075\n",
      "val Loss: 2.3018 Acc: 0.1018\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 2.3017 Acc: 0.1083\n",
      "val Loss: 2.3016 Acc: 0.1012\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 2.3015 Acc: 0.1075\n",
      "val Loss: 2.3014 Acc: 0.1014\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 2.3012 Acc: 0.1047\n",
      "val Loss: 2.3011 Acc: 0.1016\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 2.3008 Acc: 0.1056\n",
      "val Loss: 2.3007 Acc: 0.1012\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 2.3004 Acc: 0.1042\n",
      "val Loss: 2.3002 Acc: 0.1010\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 2.2999 Acc: 0.1025\n",
      "val Loss: 2.2994 Acc: 0.1010\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 2.2990 Acc: 0.1009\n",
      "val Loss: 2.2984 Acc: 0.1010\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 2.2978 Acc: 0.1020\n",
      "val Loss: 2.2969 Acc: 0.1010\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 2.2960 Acc: 0.1012\n",
      "val Loss: 2.2947 Acc: 0.1010\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 2.2931 Acc: 0.1003\n",
      "val Loss: 2.2910 Acc: 0.1010\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 2.2884 Acc: 0.1034\n",
      "val Loss: 2.2844 Acc: 0.1010\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 2.2783 Acc: 0.1032\n",
      "val Loss: 2.2685 Acc: 0.1076\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 2.2566 Acc: 0.1030\n",
      "val Loss: 2.2382 Acc: 0.1006\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 2.2247 Acc: 0.1239\n",
      "val Loss: 2.2051 Acc: 0.1490\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 2.1965 Acc: 0.1652\n",
      "val Loss: 2.1808 Acc: 0.1734\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 2.1770 Acc: 0.1824\n",
      "val Loss: 2.1652 Acc: 0.1816\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 2.1637 Acc: 0.1921\n",
      "val Loss: 2.1495 Acc: 0.2020\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 2.1501 Acc: 0.2074\n",
      "val Loss: 2.1361 Acc: 0.2220\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 2.1299 Acc: 0.2190\n",
      "val Loss: 2.1064 Acc: 0.2284\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 2.0952 Acc: 0.2269\n",
      "val Loss: 2.0643 Acc: 0.2416\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 2.0456 Acc: 0.2368\n",
      "val Loss: 2.0129 Acc: 0.2370\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-d879f15631a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n############################################################################\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-fcca070e2251>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "original_parameters = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
    "classifier_parameters = [512,4096,4096]\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for depth in range(7):\n",
    "    last_number = get_output_nodes(original_parameters)\n",
    "    classifier_params = [last_number,4096,4096]\n",
    "    if depth == 0:\n",
    "        print(\"Original network: \")\n",
    "        net = vgg16(original_parameters,classifier_parameters)\n",
    "        # print(net)\n",
    "        optimizer = optim.SGD(net.parameters(),lr=0.001)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        criterion = criterion.to(device)\n",
    "        net, hist = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=EPOCHS)\n",
    "        print(\"\\n############################################################################\\n\")\n",
    "\n",
    "  # For odd case :\n",
    "  elif depth % 2 == 1:\n",
    "    continue\n",
    "    print(\"At depth \" + str(depth) + \": \")\n",
    "    print(\"Dividing filters by 2: \")\n",
    "    original_parameters = [int(i/2) if type(i) == int else i for i in original_parameters]\n",
    "    classifier_parameters = [int(i/2) if type(i) == int else i for i in classifier_parameters]\n",
    "    print(original_parameters)\n",
    "    net = vgg16(original_parameters,classifier_parameters)\n",
    "    last_layer = [net.features[i] for i in range(len(net.features))][-1]\n",
    "    if str(last_layer) ==  'ReLU(inplace=True)':\n",
    "      net.features = nn.Sequential(*[net.features[i] for i in range(len(net.features) -1)])\n",
    "    # print(net)\n",
    "    optimizer = optim.SGD(net.parameters(),lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(device)\n",
    "    net, hist = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=EPOCHS)\n",
    "    print(\"\\n############################################################################\\n\")\n",
    "\n",
    "  # For even case :\n",
    "  elif depth % 2 == 0:\n",
    "    print(\"At depth \" + str(depth) + \": \")\n",
    "    print(\"Removing last layer: \")\n",
    "    net = vgg16(original_parameters,classifier_parameters)\n",
    "    second_last_layer = [net.features[i] for i in range(len(net.features)-1)][-1]\n",
    "    if str(second_last_layer) ==  'ReLU(inplace=True)':\n",
    "      net.features = nn.Sequential(*[net.features[i] for i in range(len(net.features) -2)])\n",
    "    else:\n",
    "      net.features = nn.Sequential(*[net.features[i] for i in range(len(net.features) -1)])\n",
    "    original_parameters = original_parameters[:-1]\n",
    "    # print(net)\n",
    "    optimizer = optim.SGD(net.parameters(),lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion = criterion.to(device)\n",
    "    net, hist = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=EPOCHS)\n",
    "    print(\"\\n############################################################################\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0x0aCxCtFrXP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "FEqjyuOel0HO",
    "ohnjQNcsxnLh",
    "LHzJ1ST07zEN"
   ],
   "include_colab_link": true,
   "name": "DSN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "24d8a07a1f724e28b30eea8c99924015": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46a08e246bdd4179abe250ceb801b81f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d11e61192804e7aac33b2e829f5b66d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "671b129abce54c699b860d3b537bfcab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f5c2d4d2c1a478cb3005665193c823a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46a08e246bdd4179abe250ceb801b81f",
      "placeholder": "​",
      "style": "IPY_MODEL_671b129abce54c699b860d3b537bfcab",
      "value": "170500096it [00:02, 81768659.46it/s]"
     }
    },
    "b71206812cc44b4da6e97bd31a779585": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c66829a33d8d406e90d70461cd870b73",
       "IPY_MODEL_7f5c2d4d2c1a478cb3005665193c823a"
      ],
      "layout": "IPY_MODEL_eee4951ca462479193a3b7c9b1c55c61"
     }
    },
    "c66829a33d8d406e90d70461cd870b73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d11e61192804e7aac33b2e829f5b66d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24d8a07a1f724e28b30eea8c99924015",
      "value": 1
     }
    },
    "eee4951ca462479193a3b7c9b1c55c61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
