{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FEqjyuOel0HO",
        "ohnjQNcsxnLh",
        "LHzJ1ST07zEN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b71206812cc44b4da6e97bd31a779585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eee4951ca462479193a3b7c9b1c55c61",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c66829a33d8d406e90d70461cd870b73",
              "IPY_MODEL_7f5c2d4d2c1a478cb3005665193c823a"
            ]
          }
        },
        "eee4951ca462479193a3b7c9b1c55c61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c66829a33d8d406e90d70461cd870b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_24d8a07a1f724e28b30eea8c99924015",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d11e61192804e7aac33b2e829f5b66d"
          }
        },
        "7f5c2d4d2c1a478cb3005665193c823a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_671b129abce54c699b860d3b537bfcab",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:02, 81768659.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46a08e246bdd4179abe250ceb801b81f"
          }
        },
        "24d8a07a1f724e28b30eea8c99924015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d11e61192804e7aac33b2e829f5b66d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "671b129abce54c699b860d3b537bfcab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46a08e246bdd4179abe250ceb801b81f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Het-Shah/IKD_DAFL/blob/master/code/notebooks/DSN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEqjyuOel0HO",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqkJI5Gt7Mmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxY2TMbdSBHD",
        "colab_type": "code",
        "outputId": "9965ffb7-78c8-4a41-b73f-f55e8d402f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Mar 16 17:51:21 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.59       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohnjQNcsxnLh",
        "colab_type": "text"
      },
      "source": [
        "# LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS8QSUVBp6Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet5(nn.Module):\n",
        "\n",
        "    def __init__(self,params):\n",
        "        super(LeNet5, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, params[0], kernel_size=(5, 5))\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        self.conv2 = nn.Conv2d(params[0], params[1], kernel_size=(5, 5))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        self.conv3 = nn.Conv2d(params[1], params[2], kernel_size=(5, 5))\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(params[2], params[3])\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(params[3], 10)\n",
        "\n",
        "    def forward(self, img, out_feature=False):\n",
        "        output = self.conv1(img)\n",
        "        output = self.relu1(output)\n",
        "        output = self.maxpool1(output)\n",
        "        output = self.conv2(output)\n",
        "        output = self.relu2(output)\n",
        "        output = self.maxpool2(output)\n",
        "        output = self.conv3(output)\n",
        "        output = self.relu3(output)\n",
        "        feature = output.view(-1, 120)\n",
        "        output = self.fc1(feature)\n",
        "        output = self.relu4(output)\n",
        "        output = self.fc2(output)\n",
        "        if out_feature == False:\n",
        "            return output\n",
        "        else:\n",
        "            return output,feature"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01SefQm0qYZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_parameters = [6,16,120,84]\n",
        "net = LeNet5(original_parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-4jGQtyqkgM",
        "colab_type": "code",
        "outputId": "dcb2d2ac-35bb-4cf2-eb98-8eaf76d523c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "net"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet5(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu2): ReLU()\n",
              "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (relu3): ReLU()\n",
              "  (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (relu4): ReLU()\n",
              "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0Rh0TO8qk_y",
        "colab_type": "code",
        "outputId": "be9793a1-5782-4de9-866f-df24cf149773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        }
      },
      "source": [
        "original_parameters = [6,16,120,84]\n",
        "for depth in range(3):\n",
        "  if depth == 0:\n",
        "    print(\"Original network: \")\n",
        "    net = LeNet5(original_parameters)\n",
        "    print(net)\n",
        "  else:\n",
        "    print(\"At depth \" + str(depth) + \": \")\n",
        "    original_parameters = [int(i/2) for i in original_parameters]\n",
        "    print(original_parameters)\n",
        "    net = LeNet5(original_parameters)\n",
        "    print(net)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original network: \n",
            "LeNet5(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu3): ReLU()\n",
            "  (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (relu4): ReLU()\n",
            "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "At depth 1: \n",
            "[3, 8, 60, 42]\n",
            "LeNet5(\n",
            "  (conv1): Conv2d(1, 3, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(3, 8, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(8, 60, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu3): ReLU()\n",
            "  (fc1): Linear(in_features=60, out_features=42, bias=True)\n",
            "  (relu4): ReLU()\n",
            "  (fc2): Linear(in_features=42, out_features=10, bias=True)\n",
            ")\n",
            "At depth 2: \n",
            "[1, 4, 30, 21]\n",
            "LeNet5(\n",
            "  (conv1): Conv2d(1, 1, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (maxpool1): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(1, 4, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (maxpool2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): Conv2d(4, 30, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (relu3): ReLU()\n",
            "  (fc1): Linear(in_features=30, out_features=21, bias=True)\n",
            "  (relu4): ReLU()\n",
            "  (fc2): Linear(in_features=21, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-WT3_hBxeju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_wLLvKwxiW5",
        "colab_type": "text"
      },
      "source": [
        "# VGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Is025MbsBiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, params, num_classes=10, init_weights=True):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = features\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(params[0] * 7 * 7, params[1]),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(params[1], params[2]),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(params[2], num_classes),\n",
        "        )\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEpzz-8CvcJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "def _vgg(arch, cfg,params, batch_norm, pretrained, progress, **kwargs):\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg, batch_norm=batch_norm),params = params, **kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT-xS2j7vFa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg16(features,params,pretrained=False,progress=True, **kwargs):\n",
        "    return _vgg('vgg16', features, params, False, pretrained, progress, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wy3P2cpv1swZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_output_nodes(params):\n",
        "  for i in reversed(params):\n",
        "    if type(i) == int:\n",
        "      last_number = i\n",
        "      break\n",
        "\n",
        "  return last_number"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHzJ1ST07zEN",
        "colab_type": "text"
      },
      "source": [
        "# Testing on Cifar-10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxoE5L9071Ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5MhrcVf73Ls",
        "colab_type": "code",
        "outputId": "463518c1-840f-4bc6-c981-f0ee026c8f03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "referenced_widgets": [
            "b71206812cc44b4da6e97bd31a779585",
            "eee4951ca462479193a3b7c9b1c55c61",
            "c66829a33d8d406e90d70461cd870b73",
            "7f5c2d4d2c1a478cb3005665193c823a",
            "24d8a07a1f724e28b30eea8c99924015",
            "5d11e61192804e7aac33b2e829f5b66d",
            "671b129abce54c699b860d3b537bfcab",
            "46a08e246bdd4179abe250ceb801b81f"
          ]
        }
      },
      "source": [
        "train_data = datasets.CIFAR10(root = 'data', \n",
        "                              train = True, \n",
        "                              download = True)\n",
        "\n",
        "means = train_data.data.mean(axis = (0,1,2)) / 255\n",
        "stds = train_data.data.std(axis = (0,1,2)) / 255\n",
        "\n",
        "print(f'Calculated means: {means}')\n",
        "print(f'Calculated stds: {stds}')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b71206812cc44b4da6e97bd31a779585",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Calculated means: [0.49139968 0.48215841 0.44653091]\n",
            "Calculated stds: [0.24703223 0.24348513 0.26158784]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSTJ5euT78tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                           transforms.RandomHorizontalFlip(),\n",
        "                           transforms.RandomRotation(10),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = means, \n",
        "                                                std = stds)\n",
        "                       ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean = means, \n",
        "                                                std = stds)\n",
        "                       ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvNdXqc68A50",
        "colab_type": "code",
        "outputId": "67fb79d0-1f5a-403d-dd3c-bc8159907e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "train_data = datasets.CIFAR10('data', \n",
        "                              train = True, \n",
        "                              download = True, \n",
        "                              transform = train_transforms)\n",
        "\n",
        "test_data = datasets.CIFAR10('data', \n",
        "                             train = False, \n",
        "                             download = True, \n",
        "                             transform = test_transforms)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XpdRreU8Ezd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_train_examples = int(len(train_data)*0.9)\n",
        "n_valid_examples = len(train_data) - n_train_examples\n",
        "\n",
        "train_data, valid_data = torch.utils.data.random_split(train_data, \n",
        "                                                       [n_train_examples, n_valid_examples])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r90hhoce8Ho-",
        "colab_type": "code",
        "outputId": "d102ef82-aa1f-404e-bab2-7519a4d8ab99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 45000\n",
            "Number of validation examples: 5000\n",
            "Number of testing examples: 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYNGQP6e8MQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator = torch.utils.data.DataLoader(train_data, \n",
        "                                             shuffle = True, \n",
        "                                             batch_size = BATCH_SIZE)\n",
        "\n",
        "valid_iterator = torch.utils.data.DataLoader(valid_data, \n",
        "                                             batch_size = BATCH_SIZE)\n",
        "\n",
        "test_iterator = torch.utils.data.DataLoader(test_data, \n",
        "                                            batch_size = BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC7ZSF4HCwmg",
        "colab_type": "text"
      },
      "source": [
        "# Building model and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45Iyu4ru9zFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "    model = model.to(device)\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMz3Xj_T-CVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloaders_dict = {'train':train_iterator,'val':valid_iterator}\n",
        "\n",
        "# Number of classes in the dataset\n",
        "num_classes = 10\n",
        "\n",
        "# Batch size for training (change depending on how much memory you have)\n",
        "batch_size = 8\n",
        "\n",
        "# Number of epochs to train for\n",
        "EPOCHS = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jigw4u4yeYAa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3cfea3f9-274d-406d-d638-668fa010eafc"
      },
      "source": [
        "original_parameters = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']\n",
        "classifier_parameters = [512,4096,4096]\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "for depth in range(7):\n",
        "  last_number = get_output_nodes(original_parameters)\n",
        "  classifier_params = [last_number,4096,4096]\n",
        "  if depth == 0:\n",
        "    continue\n",
        "    print(\"Original network: \")\n",
        "    net = vgg16(original_parameters,classifier_parameters)\n",
        "    # print(net)\n",
        "    optimizer = optim.SGD(net.parameters(),lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion = criterion.to(device)\n",
        "    net, hist = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=EPOCHS)\n",
        "    print(\"\\n############################################################################\\n\")\n",
        "\n",
        "  # For odd case :\n",
        "  elif depth % 2 == 1:\n",
        "    continue\n",
        "    print(\"At depth \" + str(depth) + \": \")\n",
        "    print(\"Dividing filters by 2: \")\n",
        "    original_parameters = [int(i/2) if type(i) == int else i for i in original_parameters]\n",
        "    classifier_parameters = [int(i/2) if type(i) == int else i for i in classifier_parameters]\n",
        "    print(original_parameters)\n",
        "    net = vgg16(original_parameters,classifier_parameters)\n",
        "    last_layer = [net.features[i] for i in range(len(net.features))][-1]\n",
        "    if str(last_layer) ==  'ReLU(inplace=True)':\n",
        "      net.features = nn.Sequential(*[net.features[i] for i in range(len(net.features) -1)])\n",
        "    # print(net)\n",
        "    optimizer = optim.SGD(net.parameters(),lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion = criterion.to(device)\n",
        "    net, hist = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=EPOCHS)\n",
        "    print(\"\\n############################################################################\\n\")\n",
        "\n",
        "  # For even case :\n",
        "  elif depth % 2 == 0:\n",
        "    print(\"At depth \" + str(depth) + \": \")\n",
        "    print(\"Removing last layer: \")\n",
        "    second_last_layer = [net.features[i] for i in range(len(net.features)-1)][-1]\n",
        "    if str(second_last_layer) ==  'ReLU(inplace=True)':\n",
        "      net.features = nn.Sequential(*[net.features[i] for i in range(len(net.features) -2)])\n",
        "    else:\n",
        "      net.features = nn.Sequential(*[net.features[i] for i in range(len(net.features) -1)])\n",
        "    original_parameters = original_parameters[:-1]\n",
        "    # print(net)\n",
        "    optimizer = optim.SGD(net.parameters(),lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    criterion = criterion.to(device)\n",
        "    net, hist = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=EPOCHS)\n",
        "    print(\"\\n############################################################################\\n\")\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At depth 2: \n",
            "Removing last layer: \n",
            "Epoch 0/199\n",
            "----------\n",
            "train Loss: 2.3026 Acc: 0.0996\n",
            "val Loss: 2.3025 Acc: 0.1022\n",
            "\n",
            "Epoch 1/199\n",
            "----------\n",
            "train Loss: 2.3025 Acc: 0.1009\n",
            "val Loss: 2.3024 Acc: 0.0878\n",
            "\n",
            "Epoch 2/199\n",
            "----------\n",
            "train Loss: 2.3024 Acc: 0.1019\n",
            "val Loss: 2.3023 Acc: 0.0996\n",
            "\n",
            "Epoch 3/199\n",
            "----------\n",
            "train Loss: 2.3023 Acc: 0.1042\n",
            "val Loss: 2.3022 Acc: 0.1006\n",
            "\n",
            "Epoch 4/199\n",
            "----------\n",
            "train Loss: 2.3021 Acc: 0.1084\n",
            "val Loss: 2.3021 Acc: 0.1012\n",
            "\n",
            "Epoch 5/199\n",
            "----------\n",
            "train Loss: 2.3020 Acc: 0.1104\n",
            "val Loss: 2.3020 Acc: 0.1012\n",
            "\n",
            "Epoch 6/199\n",
            "----------\n",
            "train Loss: 2.3019 Acc: 0.1075\n",
            "val Loss: 2.3018 Acc: 0.1018\n",
            "\n",
            "Epoch 7/199\n",
            "----------\n",
            "train Loss: 2.3017 Acc: 0.1083\n",
            "val Loss: 2.3016 Acc: 0.1012\n",
            "\n",
            "Epoch 8/199\n",
            "----------\n",
            "train Loss: 2.3015 Acc: 0.1075\n",
            "val Loss: 2.3014 Acc: 0.1014\n",
            "\n",
            "Epoch 9/199\n",
            "----------\n",
            "train Loss: 2.3012 Acc: 0.1047\n",
            "val Loss: 2.3011 Acc: 0.1016\n",
            "\n",
            "Epoch 10/199\n",
            "----------\n",
            "train Loss: 2.3008 Acc: 0.1056\n",
            "val Loss: 2.3007 Acc: 0.1012\n",
            "\n",
            "Epoch 11/199\n",
            "----------\n",
            "train Loss: 2.3004 Acc: 0.1042\n",
            "val Loss: 2.3002 Acc: 0.1010\n",
            "\n",
            "Epoch 12/199\n",
            "----------\n",
            "train Loss: 2.2999 Acc: 0.1025\n",
            "val Loss: 2.2994 Acc: 0.1010\n",
            "\n",
            "Epoch 13/199\n",
            "----------\n",
            "train Loss: 2.2990 Acc: 0.1009\n",
            "val Loss: 2.2984 Acc: 0.1010\n",
            "\n",
            "Epoch 14/199\n",
            "----------\n",
            "train Loss: 2.2978 Acc: 0.1020\n",
            "val Loss: 2.2969 Acc: 0.1010\n",
            "\n",
            "Epoch 15/199\n",
            "----------\n",
            "train Loss: 2.2960 Acc: 0.1012\n",
            "val Loss: 2.2947 Acc: 0.1010\n",
            "\n",
            "Epoch 16/199\n",
            "----------\n",
            "train Loss: 2.2931 Acc: 0.1003\n",
            "val Loss: 2.2910 Acc: 0.1010\n",
            "\n",
            "Epoch 17/199\n",
            "----------\n",
            "train Loss: 2.2884 Acc: 0.1034\n",
            "val Loss: 2.2844 Acc: 0.1010\n",
            "\n",
            "Epoch 18/199\n",
            "----------\n",
            "train Loss: 2.2783 Acc: 0.1032\n",
            "val Loss: 2.2685 Acc: 0.1076\n",
            "\n",
            "Epoch 19/199\n",
            "----------\n",
            "train Loss: 2.2566 Acc: 0.1030\n",
            "val Loss: 2.2382 Acc: 0.1006\n",
            "\n",
            "Epoch 20/199\n",
            "----------\n",
            "train Loss: 2.2247 Acc: 0.1239\n",
            "val Loss: 2.2051 Acc: 0.1490\n",
            "\n",
            "Epoch 21/199\n",
            "----------\n",
            "train Loss: 2.1965 Acc: 0.1652\n",
            "val Loss: 2.1808 Acc: 0.1734\n",
            "\n",
            "Epoch 22/199\n",
            "----------\n",
            "train Loss: 2.1770 Acc: 0.1824\n",
            "val Loss: 2.1652 Acc: 0.1816\n",
            "\n",
            "Epoch 23/199\n",
            "----------\n",
            "train Loss: 2.1637 Acc: 0.1921\n",
            "val Loss: 2.1495 Acc: 0.2020\n",
            "\n",
            "Epoch 24/199\n",
            "----------\n",
            "train Loss: 2.1501 Acc: 0.2074\n",
            "val Loss: 2.1361 Acc: 0.2220\n",
            "\n",
            "Epoch 25/199\n",
            "----------\n",
            "train Loss: 2.1299 Acc: 0.2190\n",
            "val Loss: 2.1064 Acc: 0.2284\n",
            "\n",
            "Epoch 26/199\n",
            "----------\n",
            "train Loss: 2.0952 Acc: 0.2269\n",
            "val Loss: 2.0643 Acc: 0.2416\n",
            "\n",
            "Epoch 27/199\n",
            "----------\n",
            "train Loss: 2.0456 Acc: 0.2368\n",
            "val Loss: 2.0129 Acc: 0.2370\n",
            "\n",
            "Epoch 28/199\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-d879f15631a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n############################################################################\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-fcca070e2251>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, criterion, optimizer, num_epochs, is_inception)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x0aCxCtFrXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}